{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjPHXN9ZF4lX",
        "outputId": "f7265e67-dad5-4851-d61b-73d7f5c1336f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=d6634c6eb06c2adb74ee849719e0013972d5514653b65efdf1438e892ee13d30\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=c0c0b785df613d7d375fc1eabef7bf126f18b7878715f45bac71c5279f917594\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
            "Collecting warmup_scheduler\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: warmup_scheduler\n",
            "  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2967 sha256=97645dbb6b7c9ad02f802b9fdf5006c5f4802ae5ace315a698ce3f02c62369e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
            "Successfully built warmup_scheduler\n",
            "Installing collected packages: warmup_scheduler\n",
            "Successfully installed warmup_scheduler-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install segmentation_models_pytorch\n",
        "!pip3 install warmup_scheduler\n",
        "#!pip uninstall torch -y\n",
        "#!pip install torch==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayJ3hkA8FvMq"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "# with help from Jiahao\n",
        "# created by Yu Yang\n",
        "# Date Apr 2021\n",
        "# update Date Oct 2021\n",
        "# update Date Jan 2023\n",
        "\n",
        "# updated with mixed supervision\n",
        "# updated with 2023 MICCAI sub\n",
        "# image abd mask for FA data\n",
        "# image and label for WA data\n",
        "\n",
        "# In[1]: import module\n",
        "\n",
        "\n",
        "import torch.utils.data as Data\n",
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "import segmentation_models_pytorch.losses as smp_losses\n",
        "import segmentation_models_pytorch.utils as smp_utils\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import datetime\n",
        "import random\n",
        "import sys\n",
        "#from torchsummary import summary\n",
        "#from tensorboardX import SummaryWriter\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from warmup_scheduler import GradualWarmupScheduler\n",
        "from copy import deepcopy\n",
        "import torchvision.utils as vutils\n",
        "import ssl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x43t-oqqHCR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2173151b-c961-493d-8c14-86493872920f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_G6AmqjGXbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b5b1f5-90c1-4610-80c7-f9f4abcc4fc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79a9622f0710>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# In[2]: define GPU\n",
        "\n",
        "\n",
        "#get_ipython().run_line_magic('env', 'CUDA_DEVICE_ORDER=PCI_BUS_ID')\n",
        "#get_ipython().run_line_magic('env', 'CUDA_VISIBLE_DEVICES=0')\n",
        "torch.set_num_threads(6)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# In[2]: define seed (global, just for guidance, have to re-call them everytime when it's needed\n",
        "\n",
        "seed_cus = 1\n",
        "\n",
        "random.seed(seed_cus)\n",
        "np.random.seed(seed_cus)\n",
        "torch.manual_seed(seed_cus)\n",
        "torch.cuda.manual_seed(seed_cus)\n",
        "torch.cuda.manual_seed_all(seed_cus)\n",
        "\n",
        "#torch.set_deterministic(True)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "#torch.backends.cudnn.enabled = False\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "#os.environ['PYTHONHASHSEED'] = str(2)\n",
        "\n",
        "# may want to check/print the train/val data first\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(seed_cus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PCUjAaLT0Iy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# In[4]: define dataloader\n",
        "\n",
        "\n",
        "import torch.utils.data as Data\n",
        "class My_Datasets(Data.Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, transform1=None,transform2=None):\n",
        "        super().__init__()\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "\n",
        "        self.img_list = os.listdir(self.img_dir)\n",
        "        self.mask_list = os.listdir(self.mask_dir)\n",
        "\n",
        "        self.temp = []\n",
        "\n",
        "        for img_name in os.listdir(self.img_dir):\n",
        "          mask_name = img_name.split('.')[0] + \"_0000.nii.png\"\n",
        "          img = cv2.imread(os.path.join(self.img_dir,img_name)) # here we load as RBG\n",
        "          mask= cv2.imread(os.path.join(self.mask_dir,mask_name)) # here we load as RBG\n",
        "\n",
        "          if type(mask) == type(None) or type(img) == type(None):\n",
        "            self.temp += [img_name]\n",
        "\n",
        "        print(self.temp)\n",
        "        for name in self.temp:\n",
        "          mask_name = name.split('.')[0] + \"_0000.nii.png\"\n",
        "          self.img_list.remove(name)\n",
        "          self.mask_list.remove(mask_name)\n",
        "\n",
        "\n",
        "\n",
        "        self.transform1 = transform1\n",
        "        self.transform2 = transform2\n",
        "\n",
        "    def get_blacklisted(self):\n",
        "      return self.temp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.img_list[index]\n",
        "        mask_name = self.img_list[index].split('.')[0] + \"_0000.nii.png\"\n",
        "\n",
        "\n",
        "        if img_name.endswith('.png'):\n",
        "            img = cv2.imread(os.path.join(self.img_dir,self.img_list[index])) # here we load as RBG\n",
        "            mask= cv2.imread(os.path.join(self.mask_dir,mask_name)) # here we load as RBG\n",
        "            #print(mask_name)\n",
        "\n",
        "            if type(mask) == type(None) or type(img) == type(None):\n",
        "              print(i)\n",
        "              print(mask_name)\n",
        "\n",
        "            else:\n",
        "              LABImg = img/[255.0]\n",
        "              LABmask = mask/[255.0]\n",
        "\n",
        "\n",
        "              LABImg = cv2.resize(LABImg,(224,224))\n",
        "              LABmask = cv2.resize(LABmask,(224,224))\n",
        "\n",
        "\n",
        "              LABImg = LABImg.astype(np.float32)\n",
        "              LABmask = LABmask.astype(np.float32)\n",
        "              LABmask = LABmask[:,:,0]\n",
        "\n",
        "\n",
        "\n",
        "              if self.transform1:\n",
        "                LABImg = self.transform1(LABImg)\n",
        "                LABmask = self.transform2(LABmask)\n",
        "\n",
        "\n",
        "              return LABImg, LABmask, img_name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "\n",
        "# In[5]: define transform\n",
        "\n",
        "\n",
        "transforms_img = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "])\n",
        "transforms_mask = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKaSADKgGgOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a703dbd8-16a5-4a3c-d48e-ab2bbb4484d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# In[6]: define data path and load data\n",
        "\n",
        "\n",
        "img_path = '/content/drive/My Drive/Processed data/LGE'\n",
        "mask_path = '/content/drive/My Drive/Processed data/masks'\n",
        "\n",
        "\n",
        "batch_size_train = 8\n",
        "batch_size_val = 8\n",
        "\n",
        "train_set = My_Datasets(img_path,mask_path, transform1=transforms_img,transform2=transforms_mask)\n",
        "n_train = len(train_set)\n",
        "split = n_train // 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoWkqXGI9Fwy"
      },
      "outputs": [],
      "source": [
        "\n",
        "names = os.listdir(img_path)\n",
        "\n",
        "#group names by same patient\n",
        "grouped_names = {}\n",
        "\n",
        "blacklisted = train_set.get_blacklisted()\n",
        "\n",
        "for i in range(len(names)):\n",
        "  base = names[i].split('_')[0]\n",
        "\n",
        "  if names[i] not in blacklisted:\n",
        "    if len(grouped_names) == 0:\n",
        "      grouped_names[base] = [names[i]]\n",
        "    else:\n",
        "      if base in grouped_names:\n",
        "        grouped_names[base] += [names[i]]\n",
        "      else:\n",
        "        grouped_names[base] = [names[i]]\n",
        "\n",
        "indices = list(range(n_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrioyTKqzVSI"
      },
      "outputs": [],
      "source": [
        "#Attach an index to each img\n",
        "for i in range(len(train_set)):\n",
        "  tri = train_set[i]\n",
        "  base = tri[2].split('_')[0]\n",
        "  for x in range(len(grouped_names[base])):\n",
        "    name = grouped_names[base][x]\n",
        "    if name == tri[2]:\n",
        "      grouped_names[base][x] = [name, i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-foPujTmtn-k"
      },
      "outputs": [],
      "source": [
        "#Get indices for training, validation, and testing. Put images in correct folders\n",
        "length = len(train_set)\n",
        "test_len = length // 5\n",
        "val_len = length // 5\n",
        "\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "test_indices = []\n",
        "\n",
        "test_names = []\n",
        "\n",
        "train_len = length - test_len - val_len\n",
        "for patient in grouped_names:\n",
        "  while len(train_indices) < train_len:\n",
        "    for index in range(len(grouped_names[patient])):\n",
        "      train_indices += [grouped_names[patient][index][1]]\n",
        "      if type(grouped_names[patient][index][1]) == str:\n",
        "        print(grouped_names[patient][index])\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    while len(val_indices) < val_len:\n",
        "      for index in range(len(grouped_names[patient])):\n",
        "        val_indices += [grouped_names[patient][index][1]]\n",
        "      break\n",
        "    else:\n",
        "      while len(test_indices) < test_len:\n",
        "        for index in range(len(grouped_names[patient])):\n",
        "          test_indices += [grouped_names[patient][index][1]]\n",
        "          test_names += [grouped_names[patient][index][0]]\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzv2Xst912Ib",
        "outputId": "05fefdb2-2632-4dcc-d327-5d8d06387195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All good! There are no duplicates\n"
          ]
        }
      ],
      "source": [
        "#check to make sure no indices are repeated\n",
        "check = set()\n",
        "for name in train_indices:\n",
        "  check.add(name)\n",
        "\n",
        "for name in val_indices:\n",
        "  check.add(name)\n",
        "\n",
        "for name in test_indices:\n",
        "  check.add(name)\n",
        "\n",
        "if len(check) == len(train_set):\n",
        "  print(\"All good! There are no duplicates\")\n",
        "else:\n",
        "  print(\"There are duplicates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cb4fWRs5YyB"
      },
      "outputs": [],
      "source": [
        "LGE_source = '/content/drive/My Drive/Processed data/LGE'\n",
        "LGE_destination = '/content/drive/My Drive/Internship_24_Ryan/Heart/Data/test/LGE/'\n",
        "\n",
        "mask_source = '/content/drive/My Drive/Processed data/masks/'\n",
        "mask_destination = '/content/drive/My Drive/Internship_24_Ryan/Heart/Data/test/masks/'\n",
        "\n",
        "Cine_source = '/content/drive/My Drive/Processed data/Cine/'\n",
        "Cine_destination = '/content/drive/My Drive/Internship_24_Ryan/Heart/Data/test/Cine/'\n",
        "\n",
        "\n",
        "for f in test_names:\n",
        "    if f not in blacklisted:\n",
        "      src_path = os.path.join(LGE_source, f)\n",
        "      dst_path = os.path.join(LGE_destination, f)\n",
        "      os.rename(src_path, dst_path)\n",
        "\n",
        "      mask_name = f.split('.')[0] + \"_0000.nii.png\"\n",
        "      src_path = os.path.join(mask_source, mask_name)\n",
        "      dst_path = os.path.join(mask_destination, mask_name)\n",
        "      os.rename(src_path, dst_path)\n",
        "\n",
        "      Cine_name = f.split('.')[0] + \"_0000.nii.tiff\"\n",
        "      src_path = os.path.join(Cine_source, Cine_name)\n",
        "      dst_path = os.path.join(Cine_destination, Cine_name)\n",
        "      os.rename(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKXLGsAXTiP_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}